{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZXQ532JDSCKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73e59404-4971-4230-d469-1f36f1643991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EijikekjzHUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "\n",
        "class DepthAttenuation:\n",
        "    def __init__(self, attenuation_rate=(0.0, 3.0), max_attenuation=0.0, p=0.5):\n",
        "        self.attenuation_rate = attenuation_rate\n",
        "        self.max_attenuation = max_attenuation\n",
        "        self.p = p\n",
        "\n",
        "    def apply(self, img: np.ndarray, scan_mask: np.ndarray = None) -> np.ndarray:\n",
        "        if random.random() > self.p:\n",
        "            return img\n",
        "\n",
        "        img = img.copy()\n",
        "        attenuation_map = self._generate_attenuation_map(img.shape[0], img.shape[1], scan_mask).astype(img.dtype)\n",
        "\n",
        "        # Apply the attenuation map to the image\n",
        "        if img.ndim == 2:\n",
        "            img = img * attenuation_map\n",
        "        else:\n",
        "            img = img * attenuation_map[:, :, None]\n",
        "\n",
        "        return img\n",
        "\n",
        "    def _generate_attenuation_map(self, height, width, scan_mask=None):\n",
        "        x = np.linspace(0, 1, width)\n",
        "        y = np.linspace(0, 1, height)\n",
        "        xv, yv = np.meshgrid(x, y)\n",
        "        distances = np.sqrt((xv - 0.5) ** 2 + yv**2)\n",
        "\n",
        "        # Randomly choose the attenuation rate within the specified range\n",
        "        attenuation_rate = random.uniform(*self.attenuation_rate)\n",
        "\n",
        "        # Apply bounded exponential decay based on the distance\n",
        "        attenuation_map = self._bounded_exponential_decay(distances, attenuation_rate, self.max_attenuation)\n",
        "\n",
        "        if scan_mask is not None:\n",
        "            attenuation_map = attenuation_map * scan_mask\n",
        "\n",
        "        return attenuation_map\n",
        "\n",
        "    def _bounded_exponential_decay(self, distances, attenuation_rate, max_attenuation=0):\n",
        "        intensities = (1 - max_attenuation) * np.exp(-attenuation_rate * distances) + max_attenuation\n",
        "        return intensities"
      ],
      "metadata": {
        "id": "5RIZH-hvSNoM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any, Dict, Tuple\n",
        "import numpy as np\n",
        "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
        "\n",
        "class GaussianShadow(ImageOnlyTransform):\n",
        "    def __init__(\n",
        "        self,\n",
        "        strength: float | Tuple[float, float] = (0.25, 0.8),\n",
        "        sigma_x: float | Tuple[float, float] = (0.01, 0.2),\n",
        "        sigma_y: float | Tuple[float, float] = (0.01, 0.2),\n",
        "        p: float = 0.5,\n",
        "    ) -> None:\n",
        "        super(GaussianShadow, self).__init__(p=p)\n",
        "        self.strength = strength\n",
        "        self.sigma_x = sigma_x\n",
        "        self.sigma_y = sigma_y\n",
        "\n",
        "    def apply(self, img: np.ndarray, **params: Any):\n",
        "        img = img.copy()\n",
        "\n",
        "        shadow_image = self._generate_shadow_image(\n",
        "            height=img.shape[0], width=img.shape[1], scan_mask=params[\"scan_mask\"]\n",
        "        ).astype(img.dtype)\n",
        "\n",
        "        scan_mask = params[\"scan_mask\"].astype(bool)\n",
        "        shadow_image = np.where(scan_mask, shadow_image, 1.0)\n",
        "\n",
        "        if img.ndim == 2:\n",
        "            img = img * shadow_image\n",
        "        else:\n",
        "            shadow_image = np.expand_dims(shadow_image, axis=-1)\n",
        "            img = img * shadow_image\n",
        "\n",
        "        return img\n",
        "\n",
        "    def get_params_dependent_on_data(\n",
        "        self, params: Dict[str, Any], data: Dict[str, Any]\n",
        "    ) -> Dict[str, Any]:\n",
        "        return {\"scan_mask\": data[\"scan_mask\"]}\n",
        "\n",
        "    def _generate_shadow_image(\n",
        "        self,\n",
        "        height,\n",
        "        width,\n",
        "        scan_mask,\n",
        "    ):\n",
        "        x = np.arange(0, width)\n",
        "        y = np.arange(0, height)\n",
        "        xv, yv = np.meshgrid(x, y)\n",
        "\n",
        "        mu_x = np.random.choice(x)\n",
        "        mu_y = np.random.choice(y)\n",
        "\n",
        "        if isinstance(self.strength, tuple) or isinstance(self.strength, list):\n",
        "            strength = np.random.uniform(*self.strength)\n",
        "        else:\n",
        "            strength = self.strength\n",
        "\n",
        "        if isinstance(self.sigma_x, tuple) or isinstance(self.sigma_x, list):\n",
        "            sigma_x = np.random.uniform(*self.sigma_x)\n",
        "        else:\n",
        "            sigma_x = self.sigma_x\n",
        "\n",
        "        if isinstance(self.sigma_y, tuple) or isinstance(self.sigma_y, list):\n",
        "            sigma_y = np.random.uniform(*self.sigma_y)\n",
        "        else:\n",
        "            sigma_y = self.sigma_y\n",
        "\n",
        "        sigma_x = sigma_x * width\n",
        "        sigma_y = sigma_y * height\n",
        "\n",
        "        shadow_image = 1 - strength * np.exp(\n",
        "            -((xv - mu_x) ** 2 / (2 * sigma_x**2) + (yv - mu_y) ** 2 / (2 * sigma_y**2))\n",
        "        )\n",
        "        shadow_image = shadow_image * scan_mask\n",
        "\n",
        "        return shadow_image\n"
      ],
      "metadata": {
        "id": "Iiyb4FS7SudQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any, Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
        "\n",
        "\n",
        "class HazeArtifact(ImageOnlyTransform):\n",
        "    def __init__(\n",
        "        self,\n",
        "        radius: float | Tuple[float, float] = (0.05, 0.95),\n",
        "        sigma: float | Tuple[float, float] = (0, 0.1),\n",
        "        p: float = 0.5,\n",
        "    ) -> None:\n",
        "        super(HazeArtifact, self).__init__(p=p)\n",
        "        self.radius = radius\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def apply(self, img: np.ndarray, **params: Any):\n",
        "        img = img.copy()\n",
        "\n",
        "        haze = self._generate_haze(width=img.shape[1], height=img.shape[0])\n",
        "        haze = haze * params[\"scan_mask\"]\n",
        "\n",
        "        if img.ndim == 2:\n",
        "            img = img + 0.5 * haze.astype(img.dtype)\n",
        "        else:\n",
        "            img = img + 0.5 * haze[:, :, None].astype(img.dtype)\n",
        "        img = np.clip(img, 0, 1)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def get_params_dependent_on_data(\n",
        "        self, params: Dict[str, Any], data: Dict[str, Any]\n",
        "    ) -> Dict[str, Any]:\n",
        "        return {\"scan_mask\": data[\"scan_mask\"]}\n",
        "\n",
        "    def _generate_haze(\n",
        "        self,\n",
        "        height,\n",
        "        width,\n",
        "    ):\n",
        "        x = np.linspace(0, 1, width)\n",
        "        y = np.linspace(0, 1, height)\n",
        "        xv, yv = np.meshgrid(x, y)\n",
        "\n",
        "        r = np.sqrt((xv - 0.5) ** 2 + (yv - 0) ** 2)\n",
        "\n",
        "        if isinstance(self.radius, tuple) or isinstance(self.radius, list):\n",
        "            haze_radius = np.random.uniform(*self.radius)\n",
        "        else:\n",
        "            haze_radius = self.radius\n",
        "\n",
        "        if isinstance(self.sigma, tuple) or isinstance(self.sigma, list):\n",
        "            haze_sigma = np.random.uniform(*self.sigma)\n",
        "        else:\n",
        "            haze_sigma = self.sigma\n",
        "\n",
        "        haze = np.random.uniform(0, 1, (height, width))\n",
        "        haze *= np.exp(-((r - haze_radius) ** 2) / (2 * haze_sigma**2))\n",
        "\n",
        "        return haze"
      ],
      "metadata": {
        "id": "IXDN2SsoTTS9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any, Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
        "from skimage.restoration import denoise_bilateral\n",
        "\n",
        "\n",
        "class SpeckleReduction(ImageOnlyTransform):\n",
        "    def __init__(\n",
        "        self,\n",
        "        sigma_spatial: float | Tuple[float, float] = (0.1, 2.0),\n",
        "        sigma_color: float | Tuple[float, float] = (0.0, 1.0),\n",
        "        window_size: int = 5,\n",
        "        p: float = 0.5,\n",
        "    ) -> None:\n",
        "        super(SpeckleReduction, self).__init__(p=p)\n",
        "        self.sigma_spatial = sigma_spatial\n",
        "        self.sigma_color = sigma_color\n",
        "        self.window_size = window_size\n",
        "\n",
        "    def apply(self, img: np.ndarray, **params: Any):\n",
        "        img = img.copy()\n",
        "\n",
        "        if isinstance(self.sigma_spatial, tuple) or isinstance(\n",
        "            self.sigma_spatial, list\n",
        "        ):\n",
        "            sigma_spatial = np.random.uniform(*self.sigma_spatial)\n",
        "        else:\n",
        "            sigma_spatial = self.sigma_spatial\n",
        "\n",
        "        if isinstance(self.sigma_color, tuple) or isinstance(self.sigma_color, list):\n",
        "            sigma_color = np.random.uniform(*self.sigma_color)\n",
        "        else:\n",
        "            sigma_color = self.sigma_color\n",
        "\n",
        "        channel_axis = -1 if img.ndim == 3 else None\n",
        "        denoised_img = denoise_bilateral(\n",
        "            img,\n",
        "            sigma_color=sigma_color,\n",
        "            sigma_spatial=sigma_spatial,\n",
        "            win_size=self.window_size,\n",
        "            channel_axis=channel_axis,\n",
        "        )\n",
        "\n",
        "        if img.ndim == 2:\n",
        "            # Single-channel image\n",
        "            img = np.where(params[\"scan_mask\"], denoised_img, img)\n",
        "        else:\n",
        "            # Multi-channel image\n",
        "            img = np.where(params[\"scan_mask\"][:, :, None], denoised_img, img)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def get_params_dependent_on_data(\n",
        "        self, params: Dict[str, Any], data: Dict[str, Any]\n",
        "    ) -> Dict[str, Any]:\n",
        "        return {\"scan_mask\": data[\"scan_mask\"]}"
      ],
      "metadata": {
        "id": "I-RiqxGGT7kd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Khởi tạo augmentation\n",
        "augmentations = {\n",
        "    \"depth\": DepthAttenuation((0.0, 1.0), max_attenuation=0.6, p=1.0),\n",
        "    \"gaussian\": GaussianShadow((0.25, 0.8), sigma_x=(0.01, 0.2), sigma_y=(0.01, 0.2), p=1.0),\n",
        "    \"speckle\": SpeckleReduction(sigma_spatial=(0.05, 1.0), sigma_color=(0.0, 0.6), window_size=5, p=1.0),\n",
        "    \"haze\": HazeArtifact(radius=(0.05, 0.95), sigma=(0, 0.1), p=1.0)\n",
        "}"
      ],
      "metadata": {
        "id": "Sjj0BoqC_N2f"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Đường dẫn\n",
        "dataset_path = \"/content/drive/MyDrive/OTU-2D-Dataset-main/OTU-2D-Dataset-main/dataset_split/train/images\"\n",
        "scan_mask_path = \"/content/drive/MyDrive/OTU-2D-Dataset-main/OTU-2D-Dataset-main/dataset_split/train/scan_mask\"\n",
        "base_path = \"/content/drive/MyDrive/OTU-2D-Dataset-main/OTU-2D-Dataset-main/dataset_split/train\"\n",
        "\n",
        "image_files = sorted([f for f in os.listdir(dataset_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "\n",
        "for aug_name, aug_transform in augmentations.items():\n",
        "    print(f\"\\n🔧 Đang xử lý augmentation: {aug_name.upper()}\")\n",
        "    save_dir = os.path.join(base_path, f\"augmented_{aug_name}\")\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    for image_name in tqdm(image_files, desc=aug_name):\n",
        "        base_name = os.path.splitext(image_name)[0]\n",
        "        image_path = os.path.join(dataset_path, image_name)\n",
        "        mask_name = f\"{base_name}_scan_mask.png\"\n",
        "        mask_path = os.path.join(scan_mask_path, mask_name)\n",
        "\n",
        "        if not os.path.exists(mask_path):\n",
        "            print(f\"Thiếu mask cho {image_name}\")\n",
        "            continue\n",
        "\n",
        "        # Đọc ảnh và mask\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "        if image is None:\n",
        "            print(f\"Không đọc được ảnh: {image_name}\")\n",
        "            continue\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        h, w = image.shape[:2]\n",
        "\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if mask is None:\n",
        "            print(f\"Không đọc được mask: {mask_name}\")\n",
        "            continue\n",
        "        if mask.shape != (h, w):\n",
        "            print(f\"Kích thước không khớp: {image_name} ({h}, {w}) vs {mask.shape}\")\n",
        "            continue\n",
        "\n",
        "        # Chuẩn hóa và nhị phân hóa mask\n",
        "        image_norm = image.astype(np.float32) / 255.0\n",
        "        mask_bin = (mask > 127).astype(np.float32)\n",
        "\n",
        "        try:\n",
        "            augmented_image = aug_transform.apply(image_norm, scan_mask=mask_bin)\n",
        "\n",
        "            # Xử lý NaN hoặc inf nếu có\n",
        "            if not np.isfinite(augmented_image).all():\n",
        "                print(f\"NaN/inf trong ảnh {image_name} → thay thế bằng 0\")\n",
        "                augmented_image = np.nan_to_num(augmented_image, nan=0.0, posinf=1.0, neginf=0.0)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Lỗi áp dụng {aug_name} cho {image_name}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Chuyển ảnh về uint8\n",
        "        image_uint8 = image.astype(np.uint8)\n",
        "        augmented_uint8 = (np.clip(augmented_image, 0, 1) * 255).astype(np.uint8)\n",
        "\n",
        "        # Đường dẫn lưu\n",
        "        save_original = os.path.join(save_dir, f\"original_{image_name}\")\n",
        "        save_aug = os.path.join(save_dir, f\"{aug_name}_{image_name}\")\n",
        "\n",
        "        cv2.imwrite(save_original, cv2.cvtColor(image_uint8, cv2.COLOR_RGB2BGR))\n",
        "        cv2.imwrite(save_aug, cv2.cvtColor(augmented_uint8, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "        count += 2\n",
        "\n",
        "    print(f\"augmented_{aug_name}: {count} ảnh (gồm gốc và augment)\")\n",
        "\n",
        "print(\"\\nHoàn tất toàn bộ quá trình tạo và augment ảnh.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU1IZ3aOBVZf",
        "outputId": "bd93a57a-f83f-4c66-c5c3-9ff5793420d9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔧 Đang xử lý augmentation: DEPTH\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "depth: 100%|██████████| 1177/1177 [02:24<00:00,  8.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "augmented_depth: 2354 ảnh (gồm gốc và augment)\n",
            "\n",
            "🔧 Đang xử lý augmentation: GAUSSIAN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "gaussian: 100%|██████████| 1177/1177 [02:19<00:00,  8.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "augmented_gaussian: 2354 ảnh (gồm gốc và augment)\n",
            "\n",
            "🔧 Đang xử lý augmentation: SPECKLE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "speckle:   3%|▎         | 39/1177 [00:17<10:25,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN/inf trong ảnh 1040.JPG → thay thế bằng 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "speckle:   4%|▎         | 43/1177 [00:21<14:39,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN/inf trong ảnh 1047.JPG → thay thế bằng 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "speckle:   7%|▋         | 87/1177 [00:42<09:38,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN/inf trong ảnh 1097.JPG → thay thế bằng 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "speckle:  15%|█▍        | 175/1177 [01:30<11:35,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN/inf trong ảnh 1199.JPG → thay thế bằng 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "speckle:  19%|█▉        | 228/1177 [01:55<10:39,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN/inf trong ảnh 1264.JPG → thay thế bằng 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "speckle:  24%|██▎       | 277/1177 [02:20<04:24,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN/inf trong ảnh 1319.JPG → thay thế bằng 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "speckle:  24%|██▍       | 288/1177 [02:25<07:18,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN/inf trong ảnh 1331.JPG → thay thế bằng 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "speckle:  31%|███       | 367/1177 [03:00<08:02,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN/inf trong ảnh 1420.JPG → thay thế bằng 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "speckle:  41%|████      | 480/1177 [03:54<04:57,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN/inf trong ảnh 224.JPG → thay thế bằng 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "speckle:  74%|███████▍  | 876/1177 [07:04<02:54,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN/inf trong ảnh 670.JPG → thay thế bằng 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "speckle:  78%|███████▊  | 919/1177 [07:23<02:06,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN/inf trong ảnh 718.JPG → thay thế bằng 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "speckle:  86%|████████▌ | 1015/1177 [08:09<02:15,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN/inf trong ảnh 822.JPG → thay thế bằng 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "speckle: 100%|██████████| 1177/1177 [09:28<00:00,  2.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "augmented_speckle: 2354 ảnh (gồm gốc và augment)\n",
            "\n",
            "🔧 Đang xử lý augmentation: HAZE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "haze: 100%|██████████| 1177/1177 [02:32<00:00,  7.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "augmented_haze: 2354 ảnh (gồm gốc và augment)\n",
            "\n",
            "Hoàn tất toàn bộ quá trình tạo và augment ảnh.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}